# Rank 11: Scryhall Chronicle

Track: SMB/MSP  
Rank: 11  
Previous: [Rank 10](10.md)  
Next: [Rank 12](12.md)

## Who This Is For
This rank is for SMBs and MSP-supported teams that already run baseline controls and now need dependable detection. It targets owners, managers, and IT leads who need to answer a hard question: "How quickly do we notice trouble, and can we prove it?"

## What This Rank Means
Scryhall Chronicle is centralized visibility with actionable signal. Logs from key systems are collected in one place, retention is intentional, and alert thresholds are tuned to drive response, not noise fatigue. This rank shifts security from assumptions to evidence.

## Threats This Rank Reduces
Centralized telemetry reduces high-impact blind spots:
- Delayed breach detection due to scattered logs
- Missed account takeover patterns across systems
- Incident escalation from slow triage of suspicious events
- Failed investigations caused by missing or short-retention records
- Compliance and insurance friction from weak audit evidence

## Minimum Viable Implementation (30-60 Minutes)
Start with practical centralization:
- Select one log destination for priority systems
- Ingest logs from email admin console, identity provider, and endpoints first
- Set three high-confidence alerts (admin login anomalies, MFA disable events, repeated failed login spikes)
- Define who checks alerts and response-time expectations
- Validate one test alert end-to-end

Do not chase full SIEM maturity in this first pass.

## Standard Implementation
Make detection operational:
- Expand ingestion to firewall/VPN, cloud admin actions, and critical SaaS
- Define alert severity tiers and owner handoff rules
- Establish retention windows that support investigations
- Tune noisy rules monthly to reduce alert fatigue
- Create response runbooks for top alert classes

A standard implementation balances coverage, clarity, and operational workload.

## High-Risk Implementation
For high-exposure organizations and mature MSP operations:
- Add behavioral and correlation rules across identity, endpoint, and network signals
- Implement after-hours escalation paths and pager rotation
- Apply immutable storage for critical logs
- Perform quarterly detection-gap exercises using recent incident patterns
- Track detection KPIs (MTTD, false-positive rate, escalation time)

At this stage, detection quality becomes a business resilience function.

## Standards Alignment
- NIST CSF: DE.CM and DE.AE for continuous monitoring and anomaly/event detection
- CIS Controls: Control 8 (audit log management) and Control 13 (network monitoring and defense)
- SOC 2: CC7 for monitoring, anomaly detection, and timely response evidence

## Tooling Options (Vendor-Neutral, Example Products)
- Central log aggregation/SIEM platforms
- Cloud-native logging pipelines from identity, email, and endpoint stacks
- Alert-routing tools integrated with ticketing/on-call workflows
- Example platforms may include Microsoft Sentinel, Splunk, or Elastic

## Common Mistakes
- Collecting logs without defined ownership or response SLAs
- Enabling many alerts before tuning quality thresholds
- Ignoring retention requirements until an incident occurs
- Treating dashboard setup as equivalent to detection readiness

## Verification Checklist
- Priority systems send logs to a central destination
- Alert severities and owners are documented
- At least three high-confidence alerts are tested end-to-end
- Retention policy exists and aligns with business needs
- Monthly alert-tuning review is scheduled and executed

## When To Move To Next Rank
- Detection coverage includes identity, endpoint, and key network signals
- Alert noise is low enough for reliable human response
- Incident tickets consistently reference usable log evidence
- You are ready to formalize incident command workflows at Rank 12

## Dependencies
This rank depends on earlier access and endpoint controls (roughly SMB ranks 1-10), especially identity governance and secure remote access. Without those foundations, logging volume rises while signal quality remains weak.

## Maintenance Cadence
Daily: review high-severity alerts and escalation queue.  
Weekly: confirm log pipeline health and ingestion completeness.  
Monthly: tune rules, remove noise, and test one detection scenario.

## Incident Scenario
An employee account is compromised through a phishing prompt. Previously, the company would only notice after fraudulent invoice changes. With Scryhall Chronicle, alert correlation flags unusual geolocation login, followed by MFA reset and suspicious mailbox rule creation. The incident owner isolates the account within minutes, preserves logs, and begins recovery with evidence in hand. Business impact is contained because detection moved from accidental to designed.

Track: SMB/MSP  
Rank: 11  
Previous: [Rank 10](10.md)  
Next: [Rank 12](12.md)
